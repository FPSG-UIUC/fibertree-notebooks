{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Exploring convolution\n",
    "\n",
    "First, include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "\n",
    "#%run prelude.py\n",
    "%run prelude.py --no-show-animations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Tensor(os.path.join(data_dir, \"conv-weights-a.yaml\"))\n",
    "i = Tensor(os.path.join(data_dir, \"conv-activations-a.yaml\"))\n",
    "\n",
    "displayTensor(w.setColor(\"green\"))\n",
    "displayTensor(i.setColor(\"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "o = Tensor(rank_ids=[\"P\"])\n",
    "\n",
    "canvas = createCanvas(w, i, o)\n",
    "\n",
    "w_r = w.getRoot()\n",
    "i_h = i.getRoot()\n",
    "o_p = o.getRoot()\n",
    "\n",
    "R = w_r.maxCoord() + 1\n",
    "H = i_h.maxCoord() + 1\n",
    "P = H - R + 1\n",
    "\n",
    "print(\"Convolution\")\n",
    "\n",
    "for r, (w_val) in w_r:\n",
    "    print(f\"Processing weight: ({r}, ({w_val}))\")\n",
    "    for p, (o_p_ref, i_val) in o_p << i_h.project(lambda h: h-r, (0, P)):\n",
    "        print(f\"  Processing output ({p}, ({o_p_ref}, {i_val})\")\n",
    "        o_p_ref += w_val * i_val\n",
    "        canvas.addFrame((r,), (p+r,), (p,))\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Tensor(rank_ids=[\"P\"])\n",
    "\n",
    "canvas = createCanvas(w, i, o)\n",
    "\n",
    "w_r = w.getRoot()\n",
    "i_h = i.getRoot()\n",
    "o_p = o.getRoot()\n",
    "\n",
    "R = w_r.maxCoord() + 1\n",
    "H = i_h.maxCoord() + 1\n",
    "P = H - R + 1\n",
    "\n",
    "print(\"Convolution\")\n",
    "\n",
    "for h, (i_val) in i_h:\n",
    "    print(f\"Processing input: ({h}, ({i_val}))\")\n",
    "    for p, (o_p_ref, w_val) in o_p << w_r.project(lambda r: h-r, (0, P)):\n",
    "        print(f\"  Processing output ({p}, ({o_p_ref}, {w_val})\")\n",
    "        o_p_ref += w_val * i_val\n",
    "        canvas.addFrame((h-p,), (h,), (p,))\n",
    "\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "o = Tensor(rank_ids=[\"P\"])\n",
    "\n",
    "\n",
    "w_r = w.getRoot()\n",
    "i_h = i.getRoot()\n",
    "o_p = o.getRoot()\n",
    "\n",
    "R = w_r.maxCoord() + 1\n",
    "H = i_h.maxCoord() + 1\n",
    "P = H - R + 1\n",
    "\n",
    "print(\"Convolution\")\n",
    "\n",
    "output_shape = Fiber(coords=range(P), initial=1)\n",
    "\n",
    "canvas = createCanvas(w, i, o)\n",
    "\n",
    "for p, (o_p_ref, _) in o_p << output_shape:\n",
    "    print(f\"Processing output: ({p}, ({o_p_ref}))\")\n",
    "    for h, (w_val, i_val) in w_r.project(lambda r: p+r) & i_h:\n",
    "        print(f\"  Processing weights and activations ({h}, ({w_val}, {i_val})\")\n",
    "        o_p_ref += w_val * i_val\n",
    "        canvas.addFrame((h-p,), (h,), (p,))\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Stationary - Two pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "o = Tensor(rank_ids=[\"P\"])\n",
    "\n",
    "canvas = createCanvas(w, i, o)\n",
    "\n",
    "w_r = w.getRoot()\n",
    "i_h = i.getRoot()\n",
    "o_p = o.getRoot()\n",
    "\n",
    "R = w_r.maxCoord() + 1\n",
    "H = i_h.maxCoord() + 1\n",
    "P = H - R + 1\n",
    "\n",
    "print(\"Convolution\")\n",
    "\n",
    "pass1_count = 0\n",
    "\n",
    "\n",
    "for r, (_) in w_r:\n",
    "    print(f\"Processing weight: ({r}, (_))\")\n",
    "    for p, (o_p_ref, _) in o_p << i_h.project(lambda h: h-r, (0, P)):\n",
    "        print(f\"  Calculating output ({p}, ({o_p_ref}, _)\")\n",
    "        pass1_count += 1\n",
    "        canvas.addFrame((r,), (p+r,), (p,))\n",
    "\n",
    "print(\"Pass1 count: %s\" % pass1_count)\n",
    "displayTensor(o_p)\n",
    "canvas.addFrame([], [], [])\n",
    "\n",
    "for p, (o_p_ref) in o_p:\n",
    "    print(f\"Processing output: ({p}, ({o_p_ref}))\")\n",
    "    for h, (w_val, i_val) in w_r.project(lambda r: p+r) & i_h:\n",
    "        print(f\"  Processing weights and activations ({h}, ({w_val}, {i_val})\")\n",
    "        o_p_ref += w_val * i_val\n",
    "        canvas.addFrame((h-p,), (h,), (p,))\n",
    "\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Stationary - Two pass - Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "o = Tensor(rank_ids=[\"P\"])\n",
    "\n",
    "canvas = createCanvas(w, i, o)\n",
    "\n",
    "w_r = w.getRoot()\n",
    "i_h = i.getRoot()\n",
    "o_p = o.getRoot()\n",
    "\n",
    "R = w_r.maxCoord() + 1\n",
    "H = i_h.maxCoord() + 1\n",
    "P = H - R + 1\n",
    "\n",
    "print(\"Convolution\")\n",
    "\n",
    "pass1_count = 0\n",
    "\n",
    "for r, (_) in w_r:\n",
    "    print(f\"Processing weight: ({r}, (_))\")\n",
    "    for p, (o_p_ref, _) in o_p << i_h.project(lambda h: h-r, (0, P)) - o_p:\n",
    "        print(f\"  Calculating output ({p}, ({o_p_ref}, _)\")\n",
    "        pass1_count += 1\n",
    "        canvas.addFrame((r,), (p+r,), (p,))\n",
    "\n",
    "print(\"Pass1 count: %s\" % pass1_count)\n",
    "canvas.addFrame([], [], [])\n",
    "\n",
    "for p, (o_p_ref) in o_p:\n",
    "    print(f\"Processing output: ({p}, ({o_p_ref}))\")\n",
    "    for h, (w_val, i_val) in w_r.project(lambda r: p+r) & i_h:\n",
    "        print(f\"  Processing weights and activations ({h}, ({w_val}, {i_val})\")\n",
    "        o_p_ref += w_val * i_val\n",
    "        canvas.addFrame((h-p,), (h,), (p,))\n",
    "\n",
    "\n",
    "displayCanvas(canvas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
